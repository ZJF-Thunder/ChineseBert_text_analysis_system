2023-03-29 16:02:06,623 - INFO - ——————程序运行开始——————
2023-03-29 16:02:06,623 - INFO - ——————————————————————
2023-03-29 16:02:06,658 - INFO - GPU is available
2023-03-29 16:02:07,402 - INFO - 谣言数据总量为：1538
2023-03-29 16:02:07,403 - INFO - 非谣言数据总量为：1849
2023-03-29 16:02:07,414 - INFO - 数据文本生成成功！
2023-03-29 16:02:07,429 - INFO - 成功划分训练集和测试集！
2023-03-29 16:02:15,187 - INFO - ————————————————模型训练开始————————————————
2023-03-29 16:02:15,835 - INFO - Epoch: 0, Batch: 0, Loss: 0.6887480020523071
2023-03-29 16:02:19,528 - INFO - Epoch: 0, Batch: 10, Loss: 0.6988904476165771
2023-03-29 16:02:23,238 - INFO - Epoch: 0, Batch: 20, Loss: 0.5006500482559204
2023-03-29 16:02:26,954 - INFO - Epoch: 0, Batch: 30, Loss: 0.49449294805526733
2023-03-29 16:02:30,684 - INFO - Epoch: 0, Batch: 40, Loss: 0.3427082896232605
2023-03-29 16:02:34,410 - INFO - Epoch: 0, Batch: 50, Loss: 0.3713446855545044
2023-03-29 16:02:38,144 - INFO - Epoch: 0, Batch: 60, Loss: 0.24757546186447144
2023-03-29 16:02:41,880 - INFO - Epoch: 0, Batch: 70, Loss: 0.4327618479728699
2023-03-29 16:02:45,627 - INFO - Epoch: 0, Batch: 80, Loss: 0.4180457592010498
2023-03-29 16:02:49,379 - INFO - Epoch: 0, Batch: 90, Loss: 0.3033251464366913
2023-03-29 16:02:53,136 - INFO - Epoch: 0, Batch: 100, Loss: 0.13611257076263428
2023-03-29 16:02:56,898 - INFO - Epoch: 0, Batch: 110, Loss: 0.2917347252368927
2023-03-29 16:03:00,656 - INFO - Epoch: 0, Batch: 120, Loss: 0.17324955761432648
2023-03-29 16:03:04,415 - INFO - Epoch: 0, Batch: 130, Loss: 0.08809943497180939
2023-03-29 16:03:08,187 - INFO - Epoch: 0, Batch: 140, Loss: 0.12194590270519257
2023-03-29 16:03:11,948 - INFO - Epoch: 0, Batch: 150, Loss: 0.25823354721069336
2023-03-29 16:03:15,714 - INFO - Epoch: 0, Batch: 160, Loss: 0.13717003166675568
2023-03-29 16:03:19,484 - INFO - Epoch: 0, Batch: 170, Loss: 0.10772133618593216
2023-03-29 16:03:23,255 - INFO - Epoch: 0, Batch: 180, Loss: 0.1756884902715683
2023-03-29 16:03:26,648 - INFO - Epoch [1/4], Average Loss: 0.3746
2023-03-29 16:03:27,027 - INFO - Epoch: 1, Batch: 0, Loss: 0.23367376625537872
2023-03-29 16:03:30,808 - INFO - Epoch: 1, Batch: 10, Loss: 0.11362631618976593
2023-03-29 16:03:34,580 - INFO - Epoch: 1, Batch: 20, Loss: 0.13076163828372955
2023-03-29 16:03:38,367 - INFO - Epoch: 1, Batch: 30, Loss: 0.14851658046245575
2023-03-29 16:03:42,152 - INFO - Epoch: 1, Batch: 40, Loss: 0.20119422674179077
2023-03-29 16:03:45,946 - INFO - Epoch: 1, Batch: 50, Loss: 0.39906126260757446
2023-03-29 16:03:49,745 - INFO - Epoch: 1, Batch: 60, Loss: 0.030721884220838547
2023-03-29 16:03:53,536 - INFO - Epoch: 1, Batch: 70, Loss: 0.25579237937927246
2023-03-29 16:03:57,333 - INFO - Epoch: 1, Batch: 80, Loss: 0.09801102429628372
2023-03-29 16:04:01,137 - INFO - Epoch: 1, Batch: 90, Loss: 0.04406089335680008
2023-03-29 16:04:04,932 - INFO - Epoch: 1, Batch: 100, Loss: 0.03016340732574463
2023-03-29 16:04:08,730 - INFO - Epoch: 1, Batch: 110, Loss: 0.04572124034166336
2023-03-29 16:04:12,533 - INFO - Epoch: 1, Batch: 120, Loss: 0.08062181621789932
2023-03-29 16:04:16,361 - INFO - Epoch: 1, Batch: 130, Loss: 0.07301118224859238
2023-03-29 16:04:20,178 - INFO - Epoch: 1, Batch: 140, Loss: 0.024523627012968063
2023-03-29 16:04:23,993 - INFO - Epoch: 1, Batch: 150, Loss: 0.03711376339197159
2023-03-29 16:04:27,793 - INFO - Epoch: 1, Batch: 160, Loss: 0.024576755240559578
2023-03-29 16:04:31,632 - INFO - Epoch: 1, Batch: 170, Loss: 0.20092812180519104
2023-03-29 16:04:35,444 - INFO - Epoch: 1, Batch: 180, Loss: 0.22982314229011536
2023-03-29 16:04:38,880 - INFO - Epoch [2/4], Average Loss: 0.1506
2023-03-29 16:04:39,264 - INFO - Epoch: 2, Batch: 0, Loss: 0.03836710751056671
2023-03-29 16:04:43,284 - INFO - Epoch: 2, Batch: 10, Loss: 0.038513269275426865
2023-03-29 16:04:47,406 - INFO - Epoch: 2, Batch: 20, Loss: 0.031083745881915092
2023-03-29 16:04:51,264 - INFO - Epoch: 2, Batch: 30, Loss: 0.019016925245523453
2023-03-29 16:04:55,184 - INFO - Epoch: 2, Batch: 40, Loss: 0.016663260757923126
2023-03-29 16:04:59,043 - INFO - Epoch: 2, Batch: 50, Loss: 0.23812192678451538
2023-03-29 16:05:02,921 - INFO - Epoch: 2, Batch: 60, Loss: 0.014791924506425858
2023-03-29 16:05:06,763 - INFO - Epoch: 2, Batch: 70, Loss: 0.02280428633093834
2023-03-29 16:05:10,609 - INFO - Epoch: 2, Batch: 80, Loss: 0.09215506911277771
2023-03-29 16:05:14,433 - INFO - Epoch: 2, Batch: 90, Loss: 0.03522815182805061
2023-03-29 16:05:18,316 - INFO - Epoch: 2, Batch: 100, Loss: 0.06707306206226349
2023-03-29 16:05:22,142 - INFO - Epoch: 2, Batch: 110, Loss: 0.02205483987927437
2023-03-29 16:05:25,969 - INFO - Epoch: 2, Batch: 120, Loss: 0.01987612619996071
2023-03-29 16:05:29,783 - INFO - Epoch: 2, Batch: 130, Loss: 0.0904107391834259
2023-03-29 16:05:33,697 - INFO - Epoch: 2, Batch: 140, Loss: 0.24196523427963257
2023-03-29 16:05:37,543 - INFO - Epoch: 2, Batch: 150, Loss: 0.023840609937906265
2023-03-29 16:05:41,972 - INFO - Epoch: 2, Batch: 160, Loss: 0.01987079158425331
2023-03-29 16:05:45,798 - INFO - Epoch: 2, Batch: 170, Loss: 0.011849324218928814
2023-03-29 16:05:49,623 - INFO - Epoch: 2, Batch: 180, Loss: 0.026721272617578506
2023-03-29 16:05:53,066 - INFO - Epoch [3/4], Average Loss: 0.0710
2023-03-29 16:05:53,450 - INFO - Epoch: 3, Batch: 0, Loss: 0.018270118162035942
2023-03-29 16:05:58,091 - INFO - Epoch: 3, Batch: 10, Loss: 0.05886545404791832
2023-03-29 16:06:02,313 - INFO - Epoch: 3, Batch: 20, Loss: 0.010922402143478394
2023-03-29 16:06:06,144 - INFO - Epoch: 3, Batch: 30, Loss: 0.010753634385764599
2023-03-29 16:06:09,957 - INFO - Epoch: 3, Batch: 40, Loss: 0.01200462318956852
2023-03-29 16:06:13,774 - INFO - Epoch: 3, Batch: 50, Loss: 0.16378718614578247
2023-03-29 16:06:17,591 - INFO - Epoch: 3, Batch: 60, Loss: 0.010366290807723999
2023-03-29 16:06:21,400 - INFO - Epoch: 3, Batch: 70, Loss: 0.012642093002796173
2023-03-29 16:06:25,224 - INFO - Epoch: 3, Batch: 80, Loss: 0.012718304060399532
2023-03-29 16:06:29,032 - INFO - Epoch: 3, Batch: 90, Loss: 0.013089298270642757
2023-03-29 16:06:32,851 - INFO - Epoch: 3, Batch: 100, Loss: 0.0103218462318182
2023-03-29 16:06:36,666 - INFO - Epoch: 3, Batch: 110, Loss: 0.009578889235854149
2023-03-29 16:06:40,475 - INFO - Epoch: 3, Batch: 120, Loss: 0.01191415823996067
2023-03-29 16:06:44,287 - INFO - Epoch: 3, Batch: 130, Loss: 0.009412040933966637
2023-03-29 16:06:48,116 - INFO - Epoch: 3, Batch: 140, Loss: 0.009393714368343353
2023-03-29 16:06:51,932 - INFO - Epoch: 3, Batch: 150, Loss: 0.010503040626645088
2023-03-29 16:06:55,753 - INFO - Epoch: 3, Batch: 160, Loss: 0.009838465601205826
2023-03-29 16:06:59,576 - INFO - Epoch: 3, Batch: 170, Loss: 0.00950770266354084
2023-03-29 16:07:03,396 - INFO - Epoch: 3, Batch: 180, Loss: 0.022357545793056488
2023-03-29 16:07:06,842 - INFO - Epoch [4/4], Average Loss: 0.0349
2023-03-29 16:07:06,842 - INFO - ————————————————模型训练完成————————————————
2023-03-29 16:07:06,842 - INFO - 训练开始时间：2023-03-29 16:02:15
2023-03-29 16:07:06,842 - INFO - 训练结束时间：2023-03-29 16:07:06
2023-03-29 16:07:06,842 - INFO - 模型训练总时间为: 291.66 秒
2023-03-29 16:07:07,885 - INFO - ————————————————模型保存成功————————————————
2023-03-29 16:07:08,273 - INFO - ————————————————模型测试开始————————————————
2023-03-29 16:07:08,389 - INFO - 输入预测标签为：[0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]
2023-03-29 16:07:08,389 - INFO - 输入实际标签为：[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]
2023-03-29 16:07:08,506 - INFO - 输入预测标签为：[0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1]
2023-03-29 16:07:08,507 - INFO - 输入实际标签为：[0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1]
2023-03-29 16:07:08,625 - INFO - 输入预测标签为：[1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]
2023-03-29 16:07:08,625 - INFO - 输入实际标签为：[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1]
2023-03-29 16:07:08,742 - INFO - 输入预测标签为：[0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0]
2023-03-29 16:07:08,742 - INFO - 输入实际标签为：[0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0]
2023-03-29 16:07:08,860 - INFO - 输入预测标签为：[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]
2023-03-29 16:07:08,860 - INFO - 输入实际标签为：[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]
2023-03-29 16:07:08,977 - INFO - 输入预测标签为：[1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]
2023-03-29 16:07:08,977 - INFO - 输入实际标签为：[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]
2023-03-29 16:07:09,095 - INFO - 输入预测标签为：[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1]
2023-03-29 16:07:09,096 - INFO - 输入实际标签为：[1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1]
2023-03-29 16:07:09,224 - INFO - 输入预测标签为：[1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1]
2023-03-29 16:07:09,224 - INFO - 输入实际标签为：[1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1]
2023-03-29 16:07:09,341 - INFO - 输入预测标签为：[0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0]
2023-03-29 16:07:09,341 - INFO - 输入实际标签为：[0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0]
2023-03-29 16:07:09,460 - INFO - 输入预测标签为：[1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1]
2023-03-29 16:07:09,460 - INFO - 输入实际标签为：[1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]
2023-03-29 16:07:09,577 - INFO - 输入预测标签为：[0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0]
2023-03-29 16:07:09,577 - INFO - 输入实际标签为：[0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0]
2023-03-29 16:07:09,695 - INFO - 输入预测标签为：[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]
2023-03-29 16:07:09,695 - INFO - 输入实际标签为：[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]
2023-03-29 16:07:09,812 - INFO - 输入预测标签为：[1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]
2023-03-29 16:07:09,813 - INFO - 输入实际标签为：[1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]
2023-03-29 16:07:09,930 - INFO - 输入预测标签为：[1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]
2023-03-29 16:07:09,931 - INFO - 输入实际标签为：[1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]
2023-03-29 16:07:10,049 - INFO - 输入预测标签为：[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]
2023-03-29 16:07:10,049 - INFO - 输入实际标签为：[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]
2023-03-29 16:07:10,172 - INFO - 输入预测标签为：[1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0]
2023-03-29 16:07:10,172 - INFO - 输入实际标签为：[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0]
2023-03-29 16:07:10,293 - INFO - 输入预测标签为：[0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1]
2023-03-29 16:07:10,293 - INFO - 输入实际标签为：[0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1]
2023-03-29 16:07:10,412 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]
2023-03-29 16:07:10,413 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]
2023-03-29 16:07:10,530 - INFO - 输入预测标签为：[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]
2023-03-29 16:07:10,530 - INFO - 输入实际标签为：[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]
2023-03-29 16:07:10,650 - INFO - 输入预测标签为：[0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]
2023-03-29 16:07:10,650 - INFO - 输入实际标签为：[0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]
2023-03-29 16:07:10,768 - INFO - 输入预测标签为：[1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]
2023-03-29 16:07:10,768 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0]
2023-03-29 16:07:10,768 - INFO - ————————————————模型测试结束————————————————
2023-03-29 16:07:10,768 - INFO - 总测试样本: 336个
2023-03-29 16:07:10,768 - INFO - 预测正确样本: 309个
2023-03-29 16:07:10,769 - INFO - 测试准确度: 0.919643
2023-03-29 16:07:10,769 - INFO - ————————————————预测文本类别————————————————
2023-03-29 16:07:10,791 - INFO - 这条微博有99.96%的概率为非谣言，有0.04%的概率为谣言
2023-03-29 16:07:10,791 - INFO - ——————————————————————
2023-03-29 16:07:10,791 - INFO - ——————程序运行结束——————
