2023-03-29 16:23:22,238 - INFO - ——————程序运行开始——————
2023-03-29 16:23:22,238 - INFO - ——————————————————————
2023-03-29 16:23:22,267 - INFO - GPU is available
2023-03-29 16:23:23,012 - INFO - 谣言数据总量为：1538
2023-03-29 16:23:23,012 - INFO - 非谣言数据总量为：1849
2023-03-29 16:23:23,024 - INFO - 数据文本生成成功！
2023-03-29 16:23:23,038 - INFO - 成功划分训练集和测试集！
2023-03-29 16:23:30,973 - INFO - ————————————————模型训练开始————————————————
2023-03-29 16:23:31,603 - INFO - Epoch: 0, Batch: 0, Loss: 1.0568100214004517
2023-03-29 16:23:35,286 - INFO - Epoch: 0, Batch: 10, Loss: 0.6811778545379639
2023-03-29 16:23:38,973 - INFO - Epoch: 0, Batch: 20, Loss: 0.4837970435619354
2023-03-29 16:23:42,726 - INFO - Epoch: 0, Batch: 30, Loss: 0.609524667263031
2023-03-29 16:23:46,697 - INFO - Epoch: 0, Batch: 40, Loss: 0.5954094529151917
2023-03-29 16:23:50,425 - INFO - Epoch: 0, Batch: 50, Loss: 0.2325151264667511
2023-03-29 16:23:54,160 - INFO - Epoch: 0, Batch: 60, Loss: 0.3068173825740814
2023-03-29 16:23:57,899 - INFO - Epoch: 0, Batch: 70, Loss: 0.1250978410243988
2023-03-29 16:24:01,632 - INFO - Epoch: 0, Batch: 80, Loss: 0.18957436084747314
2023-03-29 16:24:05,380 - INFO - Epoch: 0, Batch: 90, Loss: 0.40518033504486084
2023-03-29 16:24:09,119 - INFO - Epoch: 0, Batch: 100, Loss: 0.5196349024772644
2023-03-29 16:24:12,873 - INFO - Epoch: 0, Batch: 110, Loss: 0.3970349133014679
2023-03-29 16:24:16,624 - INFO - Epoch: 0, Batch: 120, Loss: 0.17470292747020721
2023-03-29 16:24:20,369 - INFO - Epoch: 0, Batch: 130, Loss: 0.36764535307884216
2023-03-29 16:24:24,126 - INFO - Epoch: 0, Batch: 140, Loss: 0.2791503965854645
2023-03-29 16:24:27,887 - INFO - Epoch: 0, Batch: 150, Loss: 0.3182019293308258
2023-03-29 16:24:31,652 - INFO - Epoch: 0, Batch: 160, Loss: 0.3328576683998108
2023-03-29 16:24:35,422 - INFO - Epoch: 0, Batch: 170, Loss: 0.22119474411010742
2023-03-29 16:24:39,189 - INFO - Epoch: 0, Batch: 180, Loss: 0.04982709512114525
2023-03-29 16:24:42,584 - INFO - Epoch [1/3], Average Loss: 0.3680
2023-03-29 16:24:42,961 - INFO - Epoch: 1, Batch: 0, Loss: 0.09259725362062454
2023-03-29 16:24:46,733 - INFO - Epoch: 1, Batch: 10, Loss: 0.3471376299858093
2023-03-29 16:24:50,514 - INFO - Epoch: 1, Batch: 20, Loss: 0.10577226430177689
2023-03-29 16:24:54,416 - INFO - Epoch: 1, Batch: 30, Loss: 0.39570069313049316
2023-03-29 16:24:58,264 - INFO - Epoch: 1, Batch: 40, Loss: 0.22678205370903015
2023-03-29 16:25:02,148 - INFO - Epoch: 1, Batch: 50, Loss: 0.07751598209142685
2023-03-29 16:25:05,936 - INFO - Epoch: 1, Batch: 60, Loss: 0.17952226102352142
2023-03-29 16:25:09,727 - INFO - Epoch: 1, Batch: 70, Loss: 0.10383237898349762
2023-03-29 16:25:13,518 - INFO - Epoch: 1, Batch: 80, Loss: 0.03262881562113762
2023-03-29 16:25:17,306 - INFO - Epoch: 1, Batch: 90, Loss: 0.31628096103668213
2023-03-29 16:25:21,098 - INFO - Epoch: 1, Batch: 100, Loss: 0.06744272261857986
2023-03-29 16:25:24,898 - INFO - Epoch: 1, Batch: 110, Loss: 0.21315684914588928
2023-03-29 16:25:28,697 - INFO - Epoch: 1, Batch: 120, Loss: 0.040316373109817505
2023-03-29 16:25:32,490 - INFO - Epoch: 1, Batch: 130, Loss: 0.062023673206567764
2023-03-29 16:25:36,310 - INFO - Epoch: 1, Batch: 140, Loss: 0.047895647585392
2023-03-29 16:25:40,111 - INFO - Epoch: 1, Batch: 150, Loss: 0.19290009140968323
2023-03-29 16:25:43,918 - INFO - Epoch: 1, Batch: 160, Loss: 0.05203032121062279
2023-03-29 16:25:47,711 - INFO - Epoch: 1, Batch: 170, Loss: 0.029965976253151894
2023-03-29 16:25:51,512 - INFO - Epoch: 1, Batch: 180, Loss: 0.015021512284874916
2023-03-29 16:25:54,930 - INFO - Epoch [2/3], Average Loss: 0.1399
2023-03-29 16:25:55,313 - INFO - Epoch: 2, Batch: 0, Loss: 0.031171342357993126
2023-03-29 16:25:59,106 - INFO - Epoch: 2, Batch: 10, Loss: 0.12949877977371216
2023-03-29 16:26:02,906 - INFO - Epoch: 2, Batch: 20, Loss: 0.03993012756109238
2023-03-29 16:26:06,712 - INFO - Epoch: 2, Batch: 30, Loss: 0.025972353294491768
2023-03-29 16:26:10,518 - INFO - Epoch: 2, Batch: 40, Loss: 0.04796913266181946
2023-03-29 16:26:14,314 - INFO - Epoch: 2, Batch: 50, Loss: 0.06106747314333916
2023-03-29 16:26:18,120 - INFO - Epoch: 2, Batch: 60, Loss: 0.01038356963545084
2023-03-29 16:26:21,918 - INFO - Epoch: 2, Batch: 70, Loss: 0.01796664111316204
2023-03-29 16:26:25,722 - INFO - Epoch: 2, Batch: 80, Loss: 0.09729837626218796
2023-03-29 16:26:29,532 - INFO - Epoch: 2, Batch: 90, Loss: 0.026874445378780365
2023-03-29 16:26:33,357 - INFO - Epoch: 2, Batch: 100, Loss: 0.011790742166340351
2023-03-29 16:26:37,255 - INFO - Epoch: 2, Batch: 110, Loss: 0.01788003370165825
2023-03-29 16:26:41,077 - INFO - Epoch: 2, Batch: 120, Loss: 0.02841227315366268
2023-03-29 16:26:44,876 - INFO - Epoch: 2, Batch: 130, Loss: 0.017078055068850517
2023-03-29 16:26:48,678 - INFO - Epoch: 2, Batch: 140, Loss: 0.0627397820353508
2023-03-29 16:26:52,472 - INFO - Epoch: 2, Batch: 150, Loss: 0.024250077083706856
2023-03-29 16:26:56,266 - INFO - Epoch: 2, Batch: 160, Loss: 0.06768962740898132
2023-03-29 16:27:00,070 - INFO - Epoch: 2, Batch: 170, Loss: 0.015366867184638977
2023-03-29 16:27:03,870 - INFO - Epoch: 2, Batch: 180, Loss: 0.011773377656936646
2023-03-29 16:27:07,301 - INFO - Epoch [3/3], Average Loss: 0.0594
2023-03-29 16:27:07,301 - INFO - ————————————————模型训练完成————————————————
2023-03-29 16:27:07,301 - INFO - 训练开始时间：2023-03-29 16:23:30
2023-03-29 16:27:07,301 - INFO - 训练结束时间：2023-03-29 16:27:07
2023-03-29 16:27:07,301 - INFO - 模型训练总时间为: 216.33 秒
2023-03-29 16:27:08,007 - INFO - ————————————————模型保存成功————————————————
2023-03-29 16:27:08,344 - INFO - ————————————————模型测试开始————————————————
2023-03-29 16:27:08,463 - INFO - 输入预测标签为：[0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]
2023-03-29 16:27:08,463 - INFO - 输入实际标签为：[0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]
2023-03-29 16:27:08,582 - INFO - 输入预测标签为：[0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]
2023-03-29 16:27:08,583 - INFO - 输入实际标签为：[0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]
2023-03-29 16:27:08,699 - INFO - 输入预测标签为：[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]
2023-03-29 16:27:08,700 - INFO - 输入实际标签为：[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]
2023-03-29 16:27:08,817 - INFO - 输入预测标签为：[1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0]
2023-03-29 16:27:08,817 - INFO - 输入实际标签为：[1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0]
2023-03-29 16:27:08,934 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0]
2023-03-29 16:27:08,934 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0]
2023-03-29 16:27:09,053 - INFO - 输入预测标签为：[1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0]
2023-03-29 16:27:09,053 - INFO - 输入实际标签为：[1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0]
2023-03-29 16:27:09,170 - INFO - 输入预测标签为：[0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0]
2023-03-29 16:27:09,170 - INFO - 输入实际标签为：[0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]
2023-03-29 16:27:09,296 - INFO - 输入预测标签为：[0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]
2023-03-29 16:27:09,297 - INFO - 输入实际标签为：[0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]
2023-03-29 16:27:09,416 - INFO - 输入预测标签为：[1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]
2023-03-29 16:27:09,416 - INFO - 输入实际标签为：[1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]
2023-03-29 16:27:09,533 - INFO - 输入预测标签为：[0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1]
2023-03-29 16:27:09,534 - INFO - 输入实际标签为：[0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1]
2023-03-29 16:27:09,653 - INFO - 输入预测标签为：[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]
2023-03-29 16:27:09,653 - INFO - 输入实际标签为：[1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]
2023-03-29 16:27:09,770 - INFO - 输入预测标签为：[0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0]
2023-03-29 16:27:09,771 - INFO - 输入实际标签为：[0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0]
2023-03-29 16:27:09,891 - INFO - 输入预测标签为：[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]
2023-03-29 16:27:09,891 - INFO - 输入实际标签为：[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]
2023-03-29 16:27:10,009 - INFO - 输入预测标签为：[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0]
2023-03-29 16:27:10,009 - INFO - 输入实际标签为：[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0]
2023-03-29 16:27:10,128 - INFO - 输入预测标签为：[0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0]
2023-03-29 16:27:10,128 - INFO - 输入实际标签为：[0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0]
2023-03-29 16:27:10,250 - INFO - 输入预测标签为：[0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]
2023-03-29 16:27:10,250 - INFO - 输入实际标签为：[0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]
2023-03-29 16:27:10,369 - INFO - 输入预测标签为：[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]
2023-03-29 16:27:10,369 - INFO - 输入实际标签为：[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]
2023-03-29 16:27:10,489 - INFO - 输入预测标签为：[1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]
2023-03-29 16:27:10,489 - INFO - 输入实际标签为：[1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1]
2023-03-29 16:27:10,607 - INFO - 输入预测标签为：[1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1]
2023-03-29 16:27:10,607 - INFO - 输入实际标签为：[1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]
2023-03-29 16:27:10,727 - INFO - 输入预测标签为：[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]
2023-03-29 16:27:10,727 - INFO - 输入实际标签为：[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]
2023-03-29 16:27:10,846 - INFO - 输入预测标签为：[1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]
2023-03-29 16:27:10,846 - INFO - 输入实际标签为：[1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]
2023-03-29 16:27:10,846 - INFO - ————————————————模型测试结束————————————————
2023-03-29 16:27:10,846 - INFO - 总测试样本: 336个
2023-03-29 16:27:10,846 - INFO - 预测正确样本: 319个
2023-03-29 16:27:10,846 - INFO - 测试准确度: 0.949405
2023-03-29 16:27:10,847 - INFO - ————————————————预测文本类别————————————————
2023-03-29 16:27:10,865 - INFO - 这条微博有97.20%的概率为非谣言，有2.80%的概率为谣言
2023-03-29 16:27:10,865 - INFO - ——————————————————————
2023-03-29 16:27:10,865 - INFO - ——————程序运行结束——————
