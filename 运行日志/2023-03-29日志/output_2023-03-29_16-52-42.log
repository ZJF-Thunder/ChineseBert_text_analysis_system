2023-03-29 16:52:42,568 - INFO - ——————程序运行开始——————
2023-03-29 16:52:42,568 - INFO - ——————————————————————
2023-03-29 16:52:42,568 - INFO - ——————输出训练参数——————
2023-03-29 16:52:42,568 - INFO - Batch_size：12
2023-03-29 16:52:42,568 - INFO - Epochs：4
2023-03-29 16:52:42,569 - INFO - Learning_rate：1e-05
2023-03-29 16:52:42,569 - INFO - max_seq_length：256
2023-03-29 16:52:42,569 - INFO - num_labels：2
2023-03-29 16:52:42,569 - INFO - ——————————————————————
2023-03-29 16:52:42,606 - INFO - GPU is available
2023-03-29 16:52:43,576 - INFO - 谣言数据总量为：1538
2023-03-29 16:52:43,576 - INFO - 非谣言数据总量为：1849
2023-03-29 16:52:43,605 - INFO - 数据文本生成成功！
2023-03-29 16:52:43,633 - INFO - 成功划分训练集和测试集！
2023-03-29 16:52:54,029 - INFO - ————————————————模型训练开始————————————————
2023-03-29 16:52:54,868 - INFO - Epoch: 0, Batch: 0, Loss: 0.7370020747184753
2023-03-29 16:53:00,504 - INFO - Epoch: 0, Batch: 10, Loss: 0.6094018220901489
2023-03-29 16:53:06,169 - INFO - Epoch: 0, Batch: 20, Loss: 0.6317087411880493
2023-03-29 16:53:11,839 - INFO - Epoch: 0, Batch: 30, Loss: 0.5147282481193542
2023-03-29 16:53:17,504 - INFO - Epoch: 0, Batch: 40, Loss: 0.5400315523147583
2023-03-29 16:53:23,482 - INFO - Epoch: 0, Batch: 50, Loss: 0.5577400922775269
2023-03-29 16:53:29,219 - INFO - Epoch: 0, Batch: 60, Loss: 0.5172691941261292
2023-03-29 16:53:34,898 - INFO - Epoch: 0, Batch: 70, Loss: 0.704157829284668
2023-03-29 16:53:40,587 - INFO - Epoch: 0, Batch: 80, Loss: 0.3061031699180603
2023-03-29 16:53:46,345 - INFO - Epoch: 0, Batch: 90, Loss: 0.27540725469589233
2023-03-29 16:53:52,050 - INFO - Epoch: 0, Batch: 100, Loss: 0.3670911490917206
2023-03-29 16:53:57,858 - INFO - Epoch: 0, Batch: 110, Loss: 0.4975569248199463
2023-03-29 16:54:03,577 - INFO - Epoch: 0, Batch: 120, Loss: 0.7529985904693604
2023-03-29 16:54:09,274 - INFO - Epoch: 0, Batch: 130, Loss: 0.23573017120361328
2023-03-29 16:54:14,985 - INFO - Epoch: 0, Batch: 140, Loss: 0.18704980611801147
2023-03-29 16:54:20,676 - INFO - Epoch: 0, Batch: 150, Loss: 0.48741626739501953
2023-03-29 16:54:26,397 - INFO - Epoch: 0, Batch: 160, Loss: 0.24652865529060364
2023-03-29 16:54:32,225 - INFO - Epoch: 0, Batch: 170, Loss: 0.26175397634506226
2023-03-29 16:54:37,988 - INFO - Epoch: 0, Batch: 180, Loss: 0.7845100164413452
2023-03-29 16:54:43,765 - INFO - Epoch: 0, Batch: 190, Loss: 0.13157153129577637
2023-03-29 16:54:49,509 - INFO - Epoch: 0, Batch: 200, Loss: 0.234577938914299
2023-03-29 16:54:55,254 - INFO - Epoch: 0, Batch: 210, Loss: 0.1823168843984604
2023-03-29 16:55:01,003 - INFO - Epoch: 0, Batch: 220, Loss: 0.4051399230957031
2023-03-29 16:55:06,723 - INFO - Epoch: 0, Batch: 230, Loss: 0.14797423779964447
2023-03-29 16:55:12,463 - INFO - Epoch: 0, Batch: 240, Loss: 0.13017058372497559
2023-03-29 16:55:18,183 - INFO - Epoch: 0, Batch: 250, Loss: 0.1554008424282074
2023-03-29 16:55:19,897 - INFO - Epoch [1/4], Average Loss: 0.3870
2023-03-29 16:55:20,466 - INFO - Epoch: 1, Batch: 0, Loss: 0.2869594097137451
2023-03-29 16:55:26,199 - INFO - Epoch: 1, Batch: 10, Loss: 0.10194351524114609
2023-03-29 16:55:31,928 - INFO - Epoch: 1, Batch: 20, Loss: 0.3571850061416626
2023-03-29 16:55:37,655 - INFO - Epoch: 1, Batch: 30, Loss: 0.07599006593227386
2023-03-29 16:55:43,365 - INFO - Epoch: 1, Batch: 40, Loss: 0.3150802254676819
2023-03-29 16:55:49,101 - INFO - Epoch: 1, Batch: 50, Loss: 0.3154928684234619
2023-03-29 16:55:54,832 - INFO - Epoch: 1, Batch: 60, Loss: 0.6874063014984131
2023-03-29 16:56:00,563 - INFO - Epoch: 1, Batch: 70, Loss: 0.24788162112236023
2023-03-29 16:56:06,287 - INFO - Epoch: 1, Batch: 80, Loss: 0.07672538608312607
2023-03-29 16:56:12,012 - INFO - Epoch: 1, Batch: 90, Loss: 0.14081017673015594
2023-03-29 16:56:17,775 - INFO - Epoch: 1, Batch: 100, Loss: 0.1491365134716034
2023-03-29 16:56:23,497 - INFO - Epoch: 1, Batch: 110, Loss: 0.15557610988616943
2023-03-29 16:56:29,228 - INFO - Epoch: 1, Batch: 120, Loss: 0.5848079919815063
2023-03-29 16:56:34,959 - INFO - Epoch: 1, Batch: 130, Loss: 0.05890747159719467
2023-03-29 16:56:40,698 - INFO - Epoch: 1, Batch: 140, Loss: 0.100126251578331
2023-03-29 16:56:46,425 - INFO - Epoch: 1, Batch: 150, Loss: 0.14968159794807434
2023-03-29 16:56:52,186 - INFO - Epoch: 1, Batch: 160, Loss: 0.11399926990270615
2023-03-29 16:56:57,922 - INFO - Epoch: 1, Batch: 170, Loss: 0.2502647638320923
2023-03-29 16:57:03,641 - INFO - Epoch: 1, Batch: 180, Loss: 0.7023071646690369
2023-03-29 16:57:09,360 - INFO - Epoch: 1, Batch: 190, Loss: 0.13419650495052338
2023-03-29 16:57:15,082 - INFO - Epoch: 1, Batch: 200, Loss: 0.04576296731829643
2023-03-29 16:57:20,818 - INFO - Epoch: 1, Batch: 210, Loss: 0.04862484335899353
2023-03-29 16:57:26,571 - INFO - Epoch: 1, Batch: 220, Loss: 0.06537231802940369
2023-03-29 16:57:32,299 - INFO - Epoch: 1, Batch: 230, Loss: 0.06742435693740845
2023-03-29 16:57:38,045 - INFO - Epoch: 1, Batch: 240, Loss: 0.1116245836019516
2023-03-29 16:57:43,797 - INFO - Epoch: 1, Batch: 250, Loss: 0.08053753525018692
2023-03-29 16:57:45,524 - INFO - Epoch [2/4], Average Loss: 0.1958
2023-03-29 16:57:46,095 - INFO - Epoch: 2, Batch: 0, Loss: 0.0593462809920311
2023-03-29 16:57:51,831 - INFO - Epoch: 2, Batch: 10, Loss: 0.030366018414497375
2023-03-29 16:57:57,573 - INFO - Epoch: 2, Batch: 20, Loss: 0.3691865801811218
2023-03-29 16:58:03,340 - INFO - Epoch: 2, Batch: 30, Loss: 0.029245927929878235
2023-03-29 16:58:09,087 - INFO - Epoch: 2, Batch: 40, Loss: 0.26942694187164307
2023-03-29 16:58:14,828 - INFO - Epoch: 2, Batch: 50, Loss: 0.13876663148403168
2023-03-29 16:58:20,566 - INFO - Epoch: 2, Batch: 60, Loss: 0.27025696635246277
2023-03-29 16:58:26,321 - INFO - Epoch: 2, Batch: 70, Loss: 0.04672270268201828
2023-03-29 16:58:32,078 - INFO - Epoch: 2, Batch: 80, Loss: 0.05212274193763733
2023-03-29 16:58:37,838 - INFO - Epoch: 2, Batch: 90, Loss: 0.02378515712916851
2023-03-29 16:58:43,593 - INFO - Epoch: 2, Batch: 100, Loss: 0.07951623201370239
2023-03-29 16:58:49,350 - INFO - Epoch: 2, Batch: 110, Loss: 0.05678356811404228
2023-03-29 16:58:55,105 - INFO - Epoch: 2, Batch: 120, Loss: 0.12476163357496262
2023-03-29 16:59:00,864 - INFO - Epoch: 2, Batch: 130, Loss: 0.024010341614484787
2023-03-29 16:59:06,626 - INFO - Epoch: 2, Batch: 140, Loss: 0.026439351961016655
2023-03-29 16:59:12,377 - INFO - Epoch: 2, Batch: 150, Loss: 0.16292636096477509
2023-03-29 16:59:18,135 - INFO - Epoch: 2, Batch: 160, Loss: 0.05932508036494255
2023-03-29 16:59:23,882 - INFO - Epoch: 2, Batch: 170, Loss: 0.24015413224697113
2023-03-29 16:59:29,637 - INFO - Epoch: 2, Batch: 180, Loss: 0.27790430188179016
2023-03-29 16:59:35,430 - INFO - Epoch: 2, Batch: 190, Loss: 0.147492915391922
2023-03-29 16:59:41,312 - INFO - Epoch: 2, Batch: 200, Loss: 0.0829697698354721
2023-03-29 16:59:47,053 - INFO - Epoch: 2, Batch: 210, Loss: 0.0594184547662735
2023-03-29 16:59:52,778 - INFO - Epoch: 2, Batch: 220, Loss: 0.059802792966365814
2023-03-29 16:59:58,503 - INFO - Epoch: 2, Batch: 230, Loss: 0.026541737839579582
2023-03-29 17:00:04,226 - INFO - Epoch: 2, Batch: 240, Loss: 0.04045097902417183
2023-03-29 17:00:09,965 - INFO - Epoch: 2, Batch: 250, Loss: 0.04699534922838211
2023-03-29 17:00:11,689 - INFO - Epoch [3/4], Average Loss: 0.1139
2023-03-29 17:00:12,256 - INFO - Epoch: 3, Batch: 0, Loss: 0.04941605031490326
2023-03-29 17:00:17,987 - INFO - Epoch: 3, Batch: 10, Loss: 0.037984490394592285
2023-03-29 17:00:23,701 - INFO - Epoch: 3, Batch: 20, Loss: 0.3250505328178406
2023-03-29 17:00:29,416 - INFO - Epoch: 3, Batch: 30, Loss: 0.02292848378419876
2023-03-29 17:00:35,123 - INFO - Epoch: 3, Batch: 40, Loss: 0.1799003779888153
2023-03-29 17:00:40,843 - INFO - Epoch: 3, Batch: 50, Loss: 0.03979142755270004
2023-03-29 17:00:46,566 - INFO - Epoch: 3, Batch: 60, Loss: 0.17026326060295105
2023-03-29 17:00:52,328 - INFO - Epoch: 3, Batch: 70, Loss: 0.025342557579278946
2023-03-29 17:00:58,092 - INFO - Epoch: 3, Batch: 80, Loss: 0.028152992948889732
2023-03-29 17:01:03,953 - INFO - Epoch: 3, Batch: 90, Loss: 0.01785203255712986
2023-03-29 17:01:09,690 - INFO - Epoch: 3, Batch: 100, Loss: 0.026297949254512787
2023-03-29 17:01:15,417 - INFO - Epoch: 3, Batch: 110, Loss: 0.06619148701429367
2023-03-29 17:01:21,141 - INFO - Epoch: 3, Batch: 120, Loss: 0.03509240970015526
2023-03-29 17:01:26,859 - INFO - Epoch: 3, Batch: 130, Loss: 0.05963551625609398
2023-03-29 17:01:32,596 - INFO - Epoch: 3, Batch: 140, Loss: 0.02000698260962963
2023-03-29 17:01:38,318 - INFO - Epoch: 3, Batch: 150, Loss: 0.017544854432344437
2023-03-29 17:01:44,030 - INFO - Epoch: 3, Batch: 160, Loss: 0.04304449260234833
2023-03-29 17:01:49,756 - INFO - Epoch: 3, Batch: 170, Loss: 0.2661958932876587
2023-03-29 17:01:55,471 - INFO - Epoch: 3, Batch: 180, Loss: 0.2765372693538666
2023-03-29 17:02:01,189 - INFO - Epoch: 3, Batch: 190, Loss: 0.01586958020925522
2023-03-29 17:02:06,917 - INFO - Epoch: 3, Batch: 200, Loss: 0.019537553191184998
2023-03-29 17:02:12,641 - INFO - Epoch: 3, Batch: 210, Loss: 0.020212437957525253
2023-03-29 17:02:18,381 - INFO - Epoch: 3, Batch: 220, Loss: 0.06372763961553574
2023-03-29 17:02:24,107 - INFO - Epoch: 3, Batch: 230, Loss: 0.024563055485486984
2023-03-29 17:02:29,848 - INFO - Epoch: 3, Batch: 240, Loss: 0.018802952021360397
2023-03-29 17:02:35,579 - INFO - Epoch: 3, Batch: 250, Loss: 0.031127197667956352
2023-03-29 17:02:37,294 - INFO - Epoch [4/4], Average Loss: 0.0672
2023-03-29 17:02:37,294 - INFO - ————————————————模型训练完成————————————————
2023-03-29 17:02:37,294 - INFO - 训练开始时间：2023-03-29 16:52:54
2023-03-29 17:02:37,294 - INFO - 训练结束时间：2023-03-29 17:02:37
2023-03-29 17:02:37,294 - INFO - 模型训练总时间为: 583.26 秒
2023-03-29 17:02:38,282 - INFO - ————————————————模型保存成功————————————————
2023-03-29 17:02:38,780 - INFO - ————————————————模型测试开始————————————————
2023-03-29 17:02:38,980 - INFO - 输入预测标签为：[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1]
2023-03-29 17:02:38,981 - INFO - 输入实际标签为：[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1]
2023-03-29 17:02:39,180 - INFO - 输入预测标签为：[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1]
2023-03-29 17:02:39,180 - INFO - 输入实际标签为：[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1]
2023-03-29 17:02:39,373 - INFO - 输入预测标签为：[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]
2023-03-29 17:02:39,373 - INFO - 输入实际标签为：[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]
2023-03-29 17:02:39,568 - INFO - 输入预测标签为：[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]
2023-03-29 17:02:39,568 - INFO - 输入实际标签为：[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]
2023-03-29 17:02:39,774 - INFO - 输入预测标签为：[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]
2023-03-29 17:02:39,774 - INFO - 输入实际标签为：[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]
2023-03-29 17:02:39,968 - INFO - 输入预测标签为：[0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]
2023-03-29 17:02:39,969 - INFO - 输入实际标签为：[0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]
2023-03-29 17:02:40,164 - INFO - 输入预测标签为：[0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]
2023-03-29 17:02:40,164 - INFO - 输入实际标签为：[0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]
2023-03-29 17:02:40,359 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]
2023-03-29 17:02:40,359 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]
2023-03-29 17:02:40,553 - INFO - 输入预测标签为：[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1]
2023-03-29 17:02:40,553 - INFO - 输入实际标签为：[1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0]
2023-03-29 17:02:40,754 - INFO - 输入预测标签为：[0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]
2023-03-29 17:02:40,754 - INFO - 输入实际标签为：[0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]
2023-03-29 17:02:40,946 - INFO - 输入预测标签为：[0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0]
2023-03-29 17:02:40,946 - INFO - 输入实际标签为：[0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0]
2023-03-29 17:02:41,144 - INFO - 输入预测标签为：[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1]
2023-03-29 17:02:41,144 - INFO - 输入实际标签为：[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1]
2023-03-29 17:02:41,342 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0]
2023-03-29 17:02:41,342 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0]
2023-03-29 17:02:41,538 - INFO - 输入预测标签为：[1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]
2023-03-29 17:02:41,539 - INFO - 输入实际标签为：[0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]
2023-03-29 17:02:41,741 - INFO - 输入预测标签为：[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]
2023-03-29 17:02:41,741 - INFO - 输入实际标签为：[1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1]
2023-03-29 17:02:41,936 - INFO - 输入预测标签为：[0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1]
2023-03-29 17:02:41,936 - INFO - 输入实际标签为：[0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1]
2023-03-29 17:02:42,132 - INFO - 输入预测标签为：[1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]
2023-03-29 17:02:42,132 - INFO - 输入实际标签为：[1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0]
2023-03-29 17:02:42,328 - INFO - 输入预测标签为：[0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]
2023-03-29 17:02:42,329 - INFO - 输入实际标签为：[0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]
2023-03-29 17:02:42,524 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]
2023-03-29 17:02:42,524 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]
2023-03-29 17:02:42,721 - INFO - 输入预测标签为：[0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]
2023-03-29 17:02:42,721 - INFO - 输入实际标签为：[0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0]
2023-03-29 17:02:42,919 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]
2023-03-29 17:02:42,919 - INFO - 输入实际标签为：[1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]
2023-03-29 17:02:43,111 - INFO - 输入预测标签为：[1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0]
2023-03-29 17:02:43,112 - INFO - 输入实际标签为：[1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0]
2023-03-29 17:02:43,308 - INFO - 输入预测标签为：[1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0]
2023-03-29 17:02:43,308 - INFO - 输入实际标签为：[1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]
2023-03-29 17:02:43,504 - INFO - 输入预测标签为：[0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1]
2023-03-29 17:02:43,504 - INFO - 输入实际标签为：[0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1]
2023-03-29 17:02:43,701 - INFO - 输入预测标签为：[1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]
2023-03-29 17:02:43,701 - INFO - 输入实际标签为：[1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]
2023-03-29 17:02:43,897 - INFO - 输入预测标签为：[1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]
2023-03-29 17:02:43,897 - INFO - 输入实际标签为：[1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0]
2023-03-29 17:02:44,095 - INFO - 输入预测标签为：[0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]
2023-03-29 17:02:44,095 - INFO - 输入实际标签为：[0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]
2023-03-29 17:02:44,291 - INFO - 输入预测标签为：[0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1]
2023-03-29 17:02:44,291 - INFO - 输入实际标签为：[0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1]
2023-03-29 17:02:44,292 - INFO - ————————————————模型测试结束————————————————
2023-03-29 17:02:44,292 - INFO - 总测试样本: 336个
2023-03-29 17:02:44,292 - INFO - 预测正确样本: 308个
2023-03-29 17:02:44,292 - INFO - 测试准确度: 0.916667
2023-03-29 17:02:44,292 - INFO - ————————————————预测文本类别————————————————
2023-03-29 17:02:44,324 - INFO - 这条微博有99.52%的概率为非谣言，有0.48%的概率为谣言
2023-03-29 17:02:44,324 - INFO - ——————————————————————
2023-03-29 17:02:44,324 - INFO - ——————程序运行结束——————
