2023-03-29 17:03:50,164 - INFO - ——————程序运行开始——————
2023-03-29 17:03:50,164 - INFO - ——————————————————————
2023-03-29 17:03:50,164 - INFO - ——————输出训练参数——————
2023-03-29 17:03:50,164 - INFO - Batch_size：12
2023-03-29 17:03:50,164 - INFO - Epochs：5
2023-03-29 17:03:50,165 - INFO - Learning_rate：1e-05
2023-03-29 17:03:50,165 - INFO - max_seq_length：256
2023-03-29 17:03:50,165 - INFO - num_labels：2
2023-03-29 17:03:50,165 - INFO - ——————————————————————
2023-03-29 17:03:50,204 - INFO - GPU is available
2023-03-29 17:03:51,820 - INFO - 谣言数据总量为：1538
2023-03-29 17:03:51,820 - INFO - 非谣言数据总量为：1849
2023-03-29 17:03:51,834 - INFO - 数据文本生成成功！
2023-03-29 17:03:51,849 - INFO - 成功划分训练集和测试集！
2023-03-29 17:04:00,730 - INFO - ————————————————模型训练开始————————————————
2023-03-29 17:04:01,627 - INFO - Epoch: 0, Batch: 0, Loss: 0.7744779586791992
2023-03-29 17:04:07,292 - INFO - Epoch: 0, Batch: 10, Loss: 0.7097924947738647
2023-03-29 17:04:12,923 - INFO - Epoch: 0, Batch: 20, Loss: 0.7275857925415039
2023-03-29 17:04:18,549 - INFO - Epoch: 0, Batch: 30, Loss: 0.6638268828392029
2023-03-29 17:04:24,206 - INFO - Epoch: 0, Batch: 40, Loss: 0.6096698641777039
2023-03-29 17:04:29,865 - INFO - Epoch: 0, Batch: 50, Loss: 0.47776374220848083
2023-03-29 17:04:35,543 - INFO - Epoch: 0, Batch: 60, Loss: 0.6036178469657898
2023-03-29 17:04:41,221 - INFO - Epoch: 0, Batch: 70, Loss: 0.5487310886383057
2023-03-29 17:04:46,912 - INFO - Epoch: 0, Batch: 80, Loss: 0.6262021660804749
2023-03-29 17:04:52,589 - INFO - Epoch: 0, Batch: 90, Loss: 0.37072503566741943
2023-03-29 17:04:58,274 - INFO - Epoch: 0, Batch: 100, Loss: 0.25921952724456787
2023-03-29 17:05:03,957 - INFO - Epoch: 0, Batch: 110, Loss: 0.305608868598938
2023-03-29 17:05:09,647 - INFO - Epoch: 0, Batch: 120, Loss: 0.130281001329422
2023-03-29 17:05:15,346 - INFO - Epoch: 0, Batch: 130, Loss: 0.31558406352996826
2023-03-29 17:05:21,044 - INFO - Epoch: 0, Batch: 140, Loss: 0.633123517036438
2023-03-29 17:05:26,744 - INFO - Epoch: 0, Batch: 150, Loss: 0.14118343591690063
2023-03-29 17:05:32,423 - INFO - Epoch: 0, Batch: 160, Loss: 0.2851889133453369
2023-03-29 17:05:38,117 - INFO - Epoch: 0, Batch: 170, Loss: 0.20760999619960785
2023-03-29 17:05:43,821 - INFO - Epoch: 0, Batch: 180, Loss: 0.14531739056110382
2023-03-29 17:05:49,530 - INFO - Epoch: 0, Batch: 190, Loss: 0.15924447774887085
2023-03-29 17:05:55,233 - INFO - Epoch: 0, Batch: 200, Loss: 0.4487150311470032
2023-03-29 17:06:00,942 - INFO - Epoch: 0, Batch: 210, Loss: 0.15986046195030212
2023-03-29 17:06:06,651 - INFO - Epoch: 0, Batch: 220, Loss: 0.3010096549987793
2023-03-29 17:06:12,368 - INFO - Epoch: 0, Batch: 230, Loss: 0.45952272415161133
2023-03-29 17:06:18,077 - INFO - Epoch: 0, Batch: 240, Loss: 0.49337369203567505
2023-03-29 17:06:23,788 - INFO - Epoch: 0, Batch: 250, Loss: 0.3132239282131195
2023-03-29 17:06:25,501 - INFO - Epoch [1/5], Average Loss: 0.4093
2023-03-29 17:06:26,073 - INFO - Epoch: 1, Batch: 0, Loss: 0.10383694618940353
2023-03-29 17:06:31,794 - INFO - Epoch: 1, Batch: 10, Loss: 0.0712396651506424
2023-03-29 17:06:37,510 - INFO - Epoch: 1, Batch: 20, Loss: 0.297171413898468
2023-03-29 17:06:43,226 - INFO - Epoch: 1, Batch: 30, Loss: 0.16134679317474365
2023-03-29 17:06:48,934 - INFO - Epoch: 1, Batch: 40, Loss: 0.522884726524353
2023-03-29 17:06:54,647 - INFO - Epoch: 1, Batch: 50, Loss: 0.05798965319991112
2023-03-29 17:07:00,364 - INFO - Epoch: 1, Batch: 60, Loss: 0.12425898760557175
2023-03-29 17:07:06,072 - INFO - Epoch: 1, Batch: 70, Loss: 0.27203673124313354
2023-03-29 17:07:11,782 - INFO - Epoch: 1, Batch: 80, Loss: 0.25507616996765137
2023-03-29 17:07:17,490 - INFO - Epoch: 1, Batch: 90, Loss: 0.058941781520843506
2023-03-29 17:07:23,194 - INFO - Epoch: 1, Batch: 100, Loss: 0.04229382798075676
2023-03-29 17:07:28,907 - INFO - Epoch: 1, Batch: 110, Loss: 0.11722502112388611
2023-03-29 17:07:34,616 - INFO - Epoch: 1, Batch: 120, Loss: 0.2652965784072876
2023-03-29 17:07:40,324 - INFO - Epoch: 1, Batch: 130, Loss: 0.07659747451543808
2023-03-29 17:07:46,038 - INFO - Epoch: 1, Batch: 140, Loss: 0.4288390874862671
2023-03-29 17:07:51,749 - INFO - Epoch: 1, Batch: 150, Loss: 0.15501070022583008
2023-03-29 17:07:57,457 - INFO - Epoch: 1, Batch: 160, Loss: 0.14524106681346893
2023-03-29 17:08:03,160 - INFO - Epoch: 1, Batch: 170, Loss: 0.04643779993057251
2023-03-29 17:08:08,864 - INFO - Epoch: 1, Batch: 180, Loss: 0.1331670731306076
2023-03-29 17:08:14,580 - INFO - Epoch: 1, Batch: 190, Loss: 0.03424173593521118
2023-03-29 17:08:20,288 - INFO - Epoch: 1, Batch: 200, Loss: 0.3934299349784851
2023-03-29 17:08:26,007 - INFO - Epoch: 1, Batch: 210, Loss: 0.047123923897743225
2023-03-29 17:08:31,704 - INFO - Epoch: 1, Batch: 220, Loss: 0.12051889300346375
2023-03-29 17:08:37,399 - INFO - Epoch: 1, Batch: 230, Loss: 0.3759136199951172
2023-03-29 17:08:43,112 - INFO - Epoch: 1, Batch: 240, Loss: 0.26845085620880127
2023-03-29 17:08:48,813 - INFO - Epoch: 1, Batch: 250, Loss: 0.2909499704837799
2023-03-29 17:08:50,525 - INFO - Epoch [2/5], Average Loss: 0.1804
2023-03-29 17:08:51,100 - INFO - Epoch: 2, Batch: 0, Loss: 0.03187870606780052
2023-03-29 17:08:56,834 - INFO - Epoch: 2, Batch: 10, Loss: 0.02240223065018654
2023-03-29 17:09:02,564 - INFO - Epoch: 2, Batch: 20, Loss: 0.12301208823919296
2023-03-29 17:09:08,282 - INFO - Epoch: 2, Batch: 30, Loss: 0.030079849064350128
2023-03-29 17:09:13,998 - INFO - Epoch: 2, Batch: 40, Loss: 0.20981866121292114
2023-03-29 17:09:19,715 - INFO - Epoch: 2, Batch: 50, Loss: 0.20823076367378235
2023-03-29 17:09:25,444 - INFO - Epoch: 2, Batch: 60, Loss: 0.11016946285963058
2023-03-29 17:09:31,164 - INFO - Epoch: 2, Batch: 70, Loss: 0.0638410672545433
2023-03-29 17:09:36,886 - INFO - Epoch: 2, Batch: 80, Loss: 0.02065350115299225
2023-03-29 17:09:42,605 - INFO - Epoch: 2, Batch: 90, Loss: 0.024491041898727417
2023-03-29 17:09:48,313 - INFO - Epoch: 2, Batch: 100, Loss: 0.06746679544448853
2023-03-29 17:09:54,021 - INFO - Epoch: 2, Batch: 110, Loss: 0.022083941847085953
2023-03-29 17:09:59,730 - INFO - Epoch: 2, Batch: 120, Loss: 0.023539764806628227
2023-03-29 17:10:05,446 - INFO - Epoch: 2, Batch: 130, Loss: 0.03371153771877289
2023-03-29 17:10:11,156 - INFO - Epoch: 2, Batch: 140, Loss: 0.4291916787624359
2023-03-29 17:10:16,875 - INFO - Epoch: 2, Batch: 150, Loss: 0.018572308123111725
2023-03-29 17:10:22,586 - INFO - Epoch: 2, Batch: 160, Loss: 0.16967853903770447
2023-03-29 17:10:28,291 - INFO - Epoch: 2, Batch: 170, Loss: 0.09268835186958313
2023-03-29 17:10:33,990 - INFO - Epoch: 2, Batch: 180, Loss: 0.058021318167448044
2023-03-29 17:10:39,716 - INFO - Epoch: 2, Batch: 190, Loss: 0.018688013777136803
2023-03-29 17:10:45,425 - INFO - Epoch: 2, Batch: 200, Loss: 0.3543398380279541
2023-03-29 17:10:51,140 - INFO - Epoch: 2, Batch: 210, Loss: 0.03386295586824417
2023-03-29 17:10:56,852 - INFO - Epoch: 2, Batch: 220, Loss: 0.0428895466029644
2023-03-29 17:11:02,555 - INFO - Epoch: 2, Batch: 230, Loss: 0.11882995814085007
2023-03-29 17:11:08,258 - INFO - Epoch: 2, Batch: 240, Loss: 0.042895734310150146
2023-03-29 17:11:13,960 - INFO - Epoch: 2, Batch: 250, Loss: 0.03806544840335846
2023-03-29 17:11:15,672 - INFO - Epoch [3/5], Average Loss: 0.0978
2023-03-29 17:11:16,244 - INFO - Epoch: 3, Batch: 0, Loss: 0.017495809122920036
2023-03-29 17:11:21,951 - INFO - Epoch: 3, Batch: 10, Loss: 0.016890086233615875
2023-03-29 17:11:27,670 - INFO - Epoch: 3, Batch: 20, Loss: 0.09081302583217621
2023-03-29 17:11:33,381 - INFO - Epoch: 3, Batch: 30, Loss: 0.024856090545654297
2023-03-29 17:11:39,091 - INFO - Epoch: 3, Batch: 40, Loss: 0.03247411176562309
2023-03-29 17:11:44,798 - INFO - Epoch: 3, Batch: 50, Loss: 0.013736680150032043
2023-03-29 17:11:50,499 - INFO - Epoch: 3, Batch: 60, Loss: 0.01830878108739853
2023-03-29 17:11:56,199 - INFO - Epoch: 3, Batch: 70, Loss: 0.07448358833789825
2023-03-29 17:12:01,907 - INFO - Epoch: 3, Batch: 80, Loss: 0.024747595191001892
2023-03-29 17:12:07,619 - INFO - Epoch: 3, Batch: 90, Loss: 0.04330460727214813
2023-03-29 17:12:13,323 - INFO - Epoch: 3, Batch: 100, Loss: 0.013987606391310692
2023-03-29 17:12:19,038 - INFO - Epoch: 3, Batch: 110, Loss: 0.012723315507173538
2023-03-29 17:12:24,742 - INFO - Epoch: 3, Batch: 120, Loss: 0.012909084558486938
2023-03-29 17:12:30,449 - INFO - Epoch: 3, Batch: 130, Loss: 0.01664530485868454
2023-03-29 17:12:36,156 - INFO - Epoch: 3, Batch: 140, Loss: 0.270022451877594
2023-03-29 17:12:41,848 - INFO - Epoch: 3, Batch: 150, Loss: 0.011763811111450195
2023-03-29 17:12:47,554 - INFO - Epoch: 3, Batch: 160, Loss: 0.012768303975462914
2023-03-29 17:12:53,260 - INFO - Epoch: 3, Batch: 170, Loss: 0.01199360005557537
2023-03-29 17:12:58,966 - INFO - Epoch: 3, Batch: 180, Loss: 0.016811497509479523
2023-03-29 17:13:04,686 - INFO - Epoch: 3, Batch: 190, Loss: 0.011162005364894867
2023-03-29 17:13:10,393 - INFO - Epoch: 3, Batch: 200, Loss: 0.31294316053390503
2023-03-29 17:13:16,104 - INFO - Epoch: 3, Batch: 210, Loss: 0.01613752916455269
2023-03-29 17:13:21,812 - INFO - Epoch: 3, Batch: 220, Loss: 0.016936060041189194
2023-03-29 17:13:27,519 - INFO - Epoch: 3, Batch: 230, Loss: 0.08456756919622421
2023-03-29 17:13:33,229 - INFO - Epoch: 3, Batch: 240, Loss: 0.02196301519870758
2023-03-29 17:13:38,942 - INFO - Epoch: 3, Batch: 250, Loss: 0.025167977437376976
2023-03-29 17:13:40,653 - INFO - Epoch [4/5], Average Loss: 0.0583
2023-03-29 17:13:41,221 - INFO - Epoch: 4, Batch: 0, Loss: 0.012948079966008663
2023-03-29 17:13:46,919 - INFO - Epoch: 4, Batch: 10, Loss: 0.012828207574784756
2023-03-29 17:13:52,634 - INFO - Epoch: 4, Batch: 20, Loss: 0.011859633028507233
2023-03-29 17:13:58,345 - INFO - Epoch: 4, Batch: 30, Loss: 0.015110435895621777
2023-03-29 17:14:04,056 - INFO - Epoch: 4, Batch: 40, Loss: 0.12937460839748383
2023-03-29 17:14:09,751 - INFO - Epoch: 4, Batch: 50, Loss: 0.010639815591275692
2023-03-29 17:14:15,464 - INFO - Epoch: 4, Batch: 60, Loss: 0.01705675944685936
2023-03-29 17:14:21,174 - INFO - Epoch: 4, Batch: 70, Loss: 0.03935573250055313
2023-03-29 17:14:26,879 - INFO - Epoch: 4, Batch: 80, Loss: 0.013888463377952576
2023-03-29 17:14:32,576 - INFO - Epoch: 4, Batch: 90, Loss: 0.011813489720225334
2023-03-29 17:14:38,283 - INFO - Epoch: 4, Batch: 100, Loss: 0.01312024425715208
2023-03-29 17:14:44,001 - INFO - Epoch: 4, Batch: 110, Loss: 0.01012383121997118
2023-03-29 17:14:49,711 - INFO - Epoch: 4, Batch: 120, Loss: 0.013717373833060265
2023-03-29 17:14:55,426 - INFO - Epoch: 4, Batch: 130, Loss: 0.014435799792408943
2023-03-29 17:15:01,132 - INFO - Epoch: 4, Batch: 140, Loss: 0.06723055243492126
2023-03-29 17:15:06,839 - INFO - Epoch: 4, Batch: 150, Loss: 0.009175561368465424
2023-03-29 17:15:12,550 - INFO - Epoch: 4, Batch: 160, Loss: 0.010774916969239712
2023-03-29 17:15:18,253 - INFO - Epoch: 4, Batch: 170, Loss: 0.012779842130839825
2023-03-29 17:15:23,964 - INFO - Epoch: 4, Batch: 180, Loss: 0.01280537061393261
2023-03-29 17:15:29,670 - INFO - Epoch: 4, Batch: 190, Loss: 0.010202024132013321
2023-03-29 17:15:35,379 - INFO - Epoch: 4, Batch: 200, Loss: 0.07107830047607422
2023-03-29 17:15:41,085 - INFO - Epoch: 4, Batch: 210, Loss: 0.013173239305615425
2023-03-29 17:15:46,798 - INFO - Epoch: 4, Batch: 220, Loss: 0.019564852118492126
2023-03-29 17:15:52,505 - INFO - Epoch: 4, Batch: 230, Loss: 0.05882370471954346
2023-03-29 17:15:58,208 - INFO - Epoch: 4, Batch: 240, Loss: 0.016936734318733215
2023-03-29 17:16:03,903 - INFO - Epoch: 4, Batch: 250, Loss: 0.017009740695357323
2023-03-29 17:16:05,612 - INFO - Epoch [5/5], Average Loss: 0.0388
2023-03-29 17:16:05,613 - INFO - ————————————————模型训练完成————————————————
2023-03-29 17:16:05,613 - INFO - 训练开始时间：2023-03-29 17:04:00
2023-03-29 17:16:05,613 - INFO - 训练结束时间：2023-03-29 17:16:05
2023-03-29 17:16:05,613 - INFO - 模型训练总时间为: 724.88 秒
2023-03-29 17:16:06,296 - INFO - ————————————————模型保存成功————————————————
2023-03-29 17:16:06,647 - INFO - ————————————————模型测试开始————————————————
2023-03-29 17:16:06,838 - INFO - 输入预测标签为：[0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1]
2023-03-29 17:16:06,838 - INFO - 输入实际标签为：[0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1]
2023-03-29 17:16:07,030 - INFO - 输入预测标签为：[1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1]
2023-03-29 17:16:07,030 - INFO - 输入实际标签为：[1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1]
2023-03-29 17:16:07,222 - INFO - 输入预测标签为：[1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]
2023-03-29 17:16:07,222 - INFO - 输入实际标签为：[1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1]
2023-03-29 17:16:07,415 - INFO - 输入预测标签为：[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]
2023-03-29 17:16:07,415 - INFO - 输入实际标签为：[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]
2023-03-29 17:16:07,621 - INFO - 输入预测标签为：[1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1]
2023-03-29 17:16:07,621 - INFO - 输入实际标签为：[1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1]
2023-03-29 17:16:07,815 - INFO - 输入预测标签为：[0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]
2023-03-29 17:16:07,815 - INFO - 输入实际标签为：[0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]
2023-03-29 17:16:08,007 - INFO - 输入预测标签为：[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1]
2023-03-29 17:16:08,007 - INFO - 输入实际标签为：[0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]
2023-03-29 17:16:08,199 - INFO - 输入预测标签为：[1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1]
2023-03-29 17:16:08,199 - INFO - 输入实际标签为：[0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1]
2023-03-29 17:16:08,395 - INFO - 输入预测标签为：[0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1]
2023-03-29 17:16:08,395 - INFO - 输入实际标签为：[1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]
2023-03-29 17:16:08,595 - INFO - 输入预测标签为：[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0]
2023-03-29 17:16:08,595 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1]
2023-03-29 17:16:08,791 - INFO - 输入预测标签为：[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]
2023-03-29 17:16:08,791 - INFO - 输入实际标签为：[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]
2023-03-29 17:16:08,986 - INFO - 输入预测标签为：[1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]
2023-03-29 17:16:08,986 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]
2023-03-29 17:16:09,179 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0]
2023-03-29 17:16:09,181 - INFO - 输入实际标签为：[1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1]
2023-03-29 17:16:09,373 - INFO - 输入预测标签为：[1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1]
2023-03-29 17:16:09,373 - INFO - 输入实际标签为：[1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1]
2023-03-29 17:16:09,571 - INFO - 输入预测标签为：[0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]
2023-03-29 17:16:09,571 - INFO - 输入实际标签为：[0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]
2023-03-29 17:16:09,766 - INFO - 输入预测标签为：[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]
2023-03-29 17:16:09,766 - INFO - 输入实际标签为：[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]
2023-03-29 17:16:09,962 - INFO - 输入预测标签为：[1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]
2023-03-29 17:16:09,962 - INFO - 输入实际标签为：[1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0]
2023-03-29 17:16:10,156 - INFO - 输入预测标签为：[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
2023-03-29 17:16:10,157 - INFO - 输入实际标签为：[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]
2023-03-29 17:16:10,350 - INFO - 输入预测标签为：[0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0]
2023-03-29 17:16:10,350 - INFO - 输入实际标签为：[0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]
2023-03-29 17:16:10,547 - INFO - 输入预测标签为：[0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1]
2023-03-29 17:16:10,547 - INFO - 输入实际标签为：[0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1]
2023-03-29 17:16:10,740 - INFO - 输入预测标签为：[0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]
2023-03-29 17:16:10,741 - INFO - 输入实际标签为：[0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]
2023-03-29 17:16:10,934 - INFO - 输入预测标签为：[0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]
2023-03-29 17:16:10,935 - INFO - 输入实际标签为：[1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1]
2023-03-29 17:16:11,131 - INFO - 输入预测标签为：[0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1]
2023-03-29 17:16:11,131 - INFO - 输入实际标签为：[0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1]
2023-03-29 17:16:11,326 - INFO - 输入预测标签为：[0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]
2023-03-29 17:16:11,326 - INFO - 输入实际标签为：[0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1]
2023-03-29 17:16:11,523 - INFO - 输入预测标签为：[0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0]
2023-03-29 17:16:11,523 - INFO - 输入实际标签为：[0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0]
2023-03-29 17:16:11,719 - INFO - 输入预测标签为：[1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0]
2023-03-29 17:16:11,720 - INFO - 输入实际标签为：[1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0]
2023-03-29 17:16:11,915 - INFO - 输入预测标签为：[0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1]
2023-03-29 17:16:11,915 - INFO - 输入实际标签为：[0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1]
2023-03-29 17:16:12,108 - INFO - 输入预测标签为：[1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0]
2023-03-29 17:16:12,109 - INFO - 输入实际标签为：[1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]
2023-03-29 17:16:12,109 - INFO - ————————————————模型测试结束————————————————
2023-03-29 17:16:12,109 - INFO - 总测试样本: 336个
2023-03-29 17:16:12,109 - INFO - 预测正确样本: 306个
2023-03-29 17:16:12,109 - INFO - 测试准确度: 0.910714
2023-03-29 17:16:12,109 - INFO - ————————————————预测文本类别————————————————
2023-03-29 17:16:12,135 - INFO - 这条微博有99.47%的概率为非谣言，有0.53%的概率为谣言
2023-03-29 17:16:12,135 - INFO - ——————————————————————
2023-03-29 17:16:12,136 - INFO - ——————程序运行结束——————
