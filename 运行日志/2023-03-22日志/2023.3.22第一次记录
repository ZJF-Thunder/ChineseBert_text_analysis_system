E:\Anaconda3\envs\pytorch18\python.exe F:/WorkSpace/毕业设计和毕业论文/毕设/Text_Categorization.py
GPU is available
谣言数据总量为：1538
非谣言数据总量为：1849
数据字典生成成功！
数据列表生成成功！
Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
F:/WorkSpace/毕业设计和毕业论文/毕设/Text_Categorization.py:194: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  (torch.tensor(input_ids).cuda(), torch.tensor(token_type_ids).cuda(), torch.tensor(attention_mask).cuda(),
Epoch: 0, Batch: 10, Loss: 0.7398784756660461
Epoch: 0, Batch: 20, Loss: 0.636773407459259
Epoch: 0, Batch: 30, Loss: 0.7415828108787537
Epoch: 0, Batch: 40, Loss: 0.6773743033409119
Epoch: 0, Batch: 50, Loss: 0.7789450883865356
Epoch: 0, Batch: 60, Loss: 0.7533060312271118
Epoch: 0, Batch: 70, Loss: 0.6242973804473877
Epoch: 0, Batch: 80, Loss: 0.639775276184082
Epoch: 0, Batch: 90, Loss: 0.791720449924469
Epoch: 0, Batch: 100, Loss: 0.700492262840271
Epoch: 0, Batch: 110, Loss: 0.8010754585266113
Epoch: 0, Batch: 120, Loss: 0.6667880415916443
Epoch: 0, Batch: 130, Loss: 0.6873530149459839
Epoch: 0, Batch: 140, Loss: 0.7988917827606201
Epoch: 0, Batch: 150, Loss: 0.7019518613815308
Epoch: 0, Batch: 160, Loss: 0.7923843860626221
Epoch: 0, Batch: 170, Loss: 0.6572214365005493
Epoch: 0, Batch: 180, Loss: 0.6373776793479919
Epoch: 0, Batch: 190, Loss: 0.7295541763305664
Epoch: 0, Batch: 200, Loss: 0.7333768010139465
Epoch: 0, Batch: 210, Loss: 0.7992868423461914
Epoch: 0, Batch: 220, Loss: 0.800957202911377
Epoch: 0, Batch: 230, Loss: 0.6479219198226929
Epoch: 0, Batch: 240, Loss: 0.7353631258010864
Epoch: 0, Batch: 250, Loss: 0.7590945959091187
Epoch: 0, Batch: 260, Loss: 0.6517112255096436
Epoch: 0, Batch: 270, Loss: 0.7871245741844177
Epoch: 0, Batch: 280, Loss: 0.6470385789871216
Epoch: 0, Batch: 290, Loss: 0.7452957630157471
Epoch: 0, Batch: 300, Loss: 0.7552647590637207
Epoch: 0, Batch: 310, Loss: 0.7526419162750244
Epoch: 0, Batch: 320, Loss: 0.6979249715805054
Epoch: 0, Batch: 330, Loss: 0.6812379360198975
Epoch: 0, Batch: 340, Loss: 0.6351250410079956
Epoch: 0, Batch: 350, Loss: 0.6220825910568237
Epoch: 0, Batch: 360, Loss: 0.7223830223083496
Epoch: 0, Batch: 370, Loss: 0.6917819380760193
Epoch: 0, Batch: 380, Loss: 0.7104861736297607
Epoch: 0, Batch: 390, Loss: 0.5580288171768188
Epoch: 0, Batch: 400, Loss: 0.7674803733825684
Epoch: 0, Batch: 410, Loss: 0.6845977902412415
Epoch: 0, Batch: 420, Loss: 0.6218445301055908
Epoch: 0, Batch: 430, Loss: 0.6069647073745728
Epoch: 0, Batch: 440, Loss: 0.786677360534668
Epoch: 0, Batch: 450, Loss: 0.6473034620285034
Epoch: 0, Batch: 460, Loss: 0.6014337539672852
Epoch: 0, Batch: 470, Loss: 0.7090542912483215
Epoch: 0, Batch: 480, Loss: 0.7219815850257874
Epoch: 0, Batch: 490, Loss: 0.7724014520645142
Epoch: 0, Batch: 500, Loss: 0.6719765663146973
Epoch: 0, Batch: 510, Loss: 0.6674209833145142
Epoch: 0, Batch: 520, Loss: 0.7051746249198914
Epoch: 0, Batch: 530, Loss: 0.7092094421386719
Epoch: 0, Batch: 540, Loss: 0.624512255191803
Epoch: 0, Batch: 550, Loss: 0.7286853790283203
Epoch: 0, Batch: 560, Loss: 0.6920929551124573
Epoch: 0, Batch: 570, Loss: 0.5048922896385193
Epoch: 0, Batch: 580, Loss: 0.6661543250083923
Epoch: 0, Batch: 590, Loss: 0.6118788719177246
Epoch: 0, Batch: 600, Loss: 0.6740192174911499
Epoch: 0, Batch: 610, Loss: 0.5569833517074585
Epoch: 0, Batch: 620, Loss: 0.7399179935455322
Epoch: 0, Batch: 630, Loss: 0.6695472002029419
Epoch: 0, Batch: 640, Loss: 0.8251059055328369
Epoch: 0, Batch: 650, Loss: 0.752730131149292
Epoch: 0, Batch: 660, Loss: 0.7454979419708252
Epoch: 0, Batch: 670, Loss: 0.7228946685791016
Epoch: 0, Batch: 680, Loss: 0.6577112674713135
Epoch: 0, Batch: 690, Loss: 0.7619661092758179
Epoch: 0, Batch: 700, Loss: 0.667320728302002
Epoch: 0, Batch: 710, Loss: 0.7011577486991882
Epoch: 0, Batch: 720, Loss: 0.805810809135437
Epoch: 0, Batch: 730, Loss: 0.6912312507629395
Epoch: 0, Batch: 740, Loss: 0.6904982328414917
Epoch: 1, Batch: 10, Loss: 0.7152696847915649
Epoch: 1, Batch: 20, Loss: 0.7121961116790771
Epoch: 1, Batch: 30, Loss: 0.6259952783584595
Epoch: 1, Batch: 40, Loss: 0.6611756682395935
Epoch: 1, Batch: 50, Loss: 0.6803485155105591
Epoch: 1, Batch: 60, Loss: 0.7314413785934448
Epoch: 1, Batch: 70, Loss: 0.6179691553115845
Epoch: 1, Batch: 80, Loss: 0.6757530570030212
Epoch: 1, Batch: 90, Loss: 0.7471331357955933
Epoch: 1, Batch: 100, Loss: 0.8457903265953064
Epoch: 1, Batch: 110, Loss: 0.8726464509963989
Epoch: 1, Batch: 120, Loss: 0.7360268831253052
Epoch: 1, Batch: 130, Loss: 0.7736950516700745
Epoch: 1, Batch: 140, Loss: 0.7865873575210571
Epoch: 1, Batch: 150, Loss: 0.6940300464630127
Epoch: 1, Batch: 160, Loss: 0.7410944700241089
Epoch: 1, Batch: 170, Loss: 0.6499818563461304
Epoch: 1, Batch: 180, Loss: 0.6292327046394348
Epoch: 1, Batch: 190, Loss: 0.6751397848129272
Epoch: 1, Batch: 200, Loss: 0.7242425680160522
Epoch: 1, Batch: 210, Loss: 0.7395609617233276
Epoch: 1, Batch: 220, Loss: 0.8624804615974426
Epoch: 1, Batch: 230, Loss: 0.6907981634140015
Epoch: 1, Batch: 240, Loss: 0.6703645586967468
Epoch: 1, Batch: 250, Loss: 0.7217565774917603
Epoch: 1, Batch: 260, Loss: 0.6728507280349731
Epoch: 1, Batch: 270, Loss: 0.7384921312332153
Epoch: 1, Batch: 280, Loss: 0.6560541391372681
Epoch: 1, Batch: 290, Loss: 0.7330654859542847
Epoch: 1, Batch: 300, Loss: 0.7039294242858887
Epoch: 1, Batch: 310, Loss: 0.7156423926353455
Epoch: 1, Batch: 320, Loss: 0.6733630895614624
Epoch: 1, Batch: 330, Loss: 0.6726861000061035
Epoch: 1, Batch: 340, Loss: 0.70854651927948
Epoch: 1, Batch: 350, Loss: 0.7215708494186401
Epoch: 1, Batch: 360, Loss: 0.6993502974510193
Epoch: 1, Batch: 370, Loss: 0.5951881408691406
Epoch: 1, Batch: 380, Loss: 0.6931961178779602
Epoch: 1, Batch: 390, Loss: 0.6158153414726257
Epoch: 1, Batch: 400, Loss: 0.7403961420059204
Epoch: 1, Batch: 410, Loss: 0.8103955984115601
Epoch: 1, Batch: 420, Loss: 0.6045360565185547
Epoch: 1, Batch: 430, Loss: 0.6726914644241333
Epoch: 1, Batch: 440, Loss: 0.8214071989059448
Epoch: 1, Batch: 450, Loss: 0.6256980895996094
Epoch: 1, Batch: 460, Loss: 0.6110876202583313
Epoch: 1, Batch: 470, Loss: 0.7206217050552368
Epoch: 1, Batch: 480, Loss: 0.7518588304519653
Epoch: 1, Batch: 490, Loss: 0.772506833076477
Epoch: 1, Batch: 500, Loss: 0.6883219480514526
Epoch: 1, Batch: 510, Loss: 0.768900990486145
Epoch: 1, Batch: 520, Loss: 0.6517393589019775
Epoch: 1, Batch: 530, Loss: 0.6674079895019531
Epoch: 1, Batch: 540, Loss: 0.6437022686004639
Epoch: 1, Batch: 550, Loss: 0.7174160480499268
Epoch: 1, Batch: 560, Loss: 0.6893116235733032
Epoch: 1, Batch: 570, Loss: 0.49940070509910583
Epoch: 1, Batch: 580, Loss: 0.7256790995597839
Epoch: 1, Batch: 590, Loss: 0.5758424401283264
Epoch: 1, Batch: 600, Loss: 0.793834924697876
Epoch: 1, Batch: 610, Loss: 0.6137681007385254
Epoch: 1, Batch: 620, Loss: 0.7885043621063232
Epoch: 1, Batch: 630, Loss: 0.6594206094741821
Epoch: 1, Batch: 640, Loss: 0.8302625417709351
Epoch: 1, Batch: 650, Loss: 0.6844786405563354
Epoch: 1, Batch: 660, Loss: 0.7315497398376465
Epoch: 1, Batch: 670, Loss: 0.7160394191741943
Epoch: 1, Batch: 680, Loss: 0.6706097722053528
Epoch: 1, Batch: 690, Loss: 0.7182009220123291
Epoch: 1, Batch: 700, Loss: 0.6608045101165771
Epoch: 1, Batch: 710, Loss: 0.7149242162704468
Epoch: 1, Batch: 720, Loss: 0.7737815976142883
Epoch: 1, Batch: 730, Loss: 0.7383702993392944
Epoch: 1, Batch: 740, Loss: 0.7526232004165649
Epoch: 2, Batch: 10, Loss: 0.6688590049743652
Epoch: 2, Batch: 20, Loss: 0.7571367025375366
Epoch: 2, Batch: 30, Loss: 0.7002414464950562
Epoch: 2, Batch: 40, Loss: 0.6699390411376953
Epoch: 2, Batch: 50, Loss: 0.7203909754753113
Epoch: 2, Batch: 60, Loss: 0.6784018278121948
Epoch: 2, Batch: 70, Loss: 0.6855361461639404
Epoch: 2, Batch: 80, Loss: 0.6957818269729614
Epoch: 2, Batch: 90, Loss: 0.7072572708129883
Epoch: 2, Batch: 100, Loss: 0.8601933121681213
Epoch: 2, Batch: 110, Loss: 0.757347822189331
Epoch: 2, Batch: 120, Loss: 0.7112847566604614
Epoch: 2, Batch: 130, Loss: 0.688866376876831
Epoch: 2, Batch: 140, Loss: 0.7174080014228821
Epoch: 2, Batch: 150, Loss: 0.6741302013397217
Epoch: 2, Batch: 160, Loss: 0.765837550163269
Epoch: 2, Batch: 170, Loss: 0.6809231042861938
Epoch: 2, Batch: 180, Loss: 0.6747577786445618
Epoch: 2, Batch: 190, Loss: 0.7011759281158447
Epoch: 2, Batch: 200, Loss: 0.7077898979187012
Epoch: 2, Batch: 210, Loss: 0.7228286266326904
Epoch: 2, Batch: 220, Loss: 0.8142968416213989
Epoch: 2, Batch: 230, Loss: 0.7638378739356995
Epoch: 2, Batch: 240, Loss: 0.7391213774681091
Epoch: 2, Batch: 250, Loss: 0.7174407839775085
Epoch: 2, Batch: 260, Loss: 0.6220809817314148
Epoch: 2, Batch: 270, Loss: 0.6554880142211914
Epoch: 2, Batch: 280, Loss: 0.6600496172904968
Epoch: 2, Batch: 290, Loss: 0.7223649621009827
Epoch: 2, Batch: 300, Loss: 0.7732129096984863
Epoch: 2, Batch: 310, Loss: 0.79155033826828
Epoch: 2, Batch: 320, Loss: 0.6603846549987793
Epoch: 2, Batch: 330, Loss: 0.7416747808456421
Epoch: 2, Batch: 340, Loss: 0.6677713990211487
Epoch: 2, Batch: 350, Loss: 0.6966309547424316
Epoch: 2, Batch: 360, Loss: 0.6657155752182007
Epoch: 2, Batch: 370, Loss: 0.6785154342651367
Epoch: 2, Batch: 380, Loss: 0.7173893451690674
Epoch: 2, Batch: 390, Loss: 0.6256034970283508
Epoch: 2, Batch: 400, Loss: 0.7692716121673584
Epoch: 2, Batch: 410, Loss: 0.8331971168518066
Epoch: 2, Batch: 420, Loss: 0.6425672769546509
Epoch: 2, Batch: 430, Loss: 0.7062845826148987
Epoch: 2, Batch: 440, Loss: 0.7492183446884155
Epoch: 2, Batch: 450, Loss: 0.6479816436767578
Epoch: 2, Batch: 460, Loss: 0.6164336204528809
Epoch: 2, Batch: 470, Loss: 0.6749497652053833
Epoch: 2, Batch: 480, Loss: 0.7088255882263184
Epoch: 2, Batch: 490, Loss: 0.7767836451530457
Epoch: 2, Batch: 500, Loss: 0.6933176517486572
Epoch: 2, Batch: 510, Loss: 0.7562768459320068
Epoch: 2, Batch: 520, Loss: 0.6639413833618164
Epoch: 2, Batch: 530, Loss: 0.6809682846069336
Epoch: 2, Batch: 540, Loss: 0.6200249195098877
Epoch: 2, Batch: 550, Loss: 0.7277577519416809
Epoch: 2, Batch: 560, Loss: 0.6704219579696655
Epoch: 2, Batch: 570, Loss: 0.6024699807167053
Epoch: 2, Batch: 580, Loss: 0.7012492418289185
Epoch: 2, Batch: 590, Loss: 0.6721422672271729
Epoch: 2, Batch: 600, Loss: 0.6968849897384644
Epoch: 2, Batch: 610, Loss: 0.6216272115707397
Epoch: 2, Batch: 620, Loss: 0.7392591238021851
Epoch: 2, Batch: 630, Loss: 0.674053430557251
Epoch: 2, Batch: 640, Loss: 0.8511022925376892
Epoch: 2, Batch: 650, Loss: 0.6663678884506226
Epoch: 2, Batch: 660, Loss: 0.6781181693077087
Epoch: 2, Batch: 670, Loss: 0.6710995435714722
Epoch: 2, Batch: 680, Loss: 0.7113244533538818
Epoch: 2, Batch: 690, Loss: 0.7034120559692383
Epoch: 2, Batch: 700, Loss: 0.6831018328666687
Epoch: 2, Batch: 710, Loss: 0.6716498732566833
Epoch: 2, Batch: 720, Loss: 0.7380914092063904
Epoch: 2, Batch: 730, Loss: 0.6857914328575134
Epoch: 2, Batch: 740, Loss: 0.7278631925582886
Epoch: 3, Batch: 10, Loss: 0.7201363444328308
Epoch: 3, Batch: 20, Loss: 0.716491162776947
Epoch: 3, Batch: 30, Loss: 0.6799983978271484
Epoch: 3, Batch: 40, Loss: 0.683082103729248
Epoch: 3, Batch: 50, Loss: 0.6882137060165405
Epoch: 3, Batch: 60, Loss: 0.6558471322059631
Epoch: 3, Batch: 70, Loss: 0.6300675868988037
Epoch: 3, Batch: 80, Loss: 0.6469854116439819
Epoch: 3, Batch: 90, Loss: 0.6771374940872192
Epoch: 3, Batch: 100, Loss: 0.7639822959899902
Epoch: 3, Batch: 110, Loss: 0.7557705640792847
Epoch: 3, Batch: 120, Loss: 0.6819175481796265
Epoch: 3, Batch: 130, Loss: 0.7287083864212036
Epoch: 3, Batch: 140, Loss: 0.7589807510375977
Epoch: 3, Batch: 150, Loss: 0.6993325352668762
Epoch: 3, Batch: 160, Loss: 0.700537919998169
Epoch: 3, Batch: 170, Loss: 0.6582398414611816
Epoch: 3, Batch: 180, Loss: 0.6808264255523682
Epoch: 3, Batch: 190, Loss: 0.7777729034423828
Epoch: 3, Batch: 200, Loss: 0.7089918851852417
Epoch: 3, Batch: 210, Loss: 0.8042598962783813
Epoch: 3, Batch: 220, Loss: 0.7679302096366882
Epoch: 3, Batch: 230, Loss: 0.7928426861763
Epoch: 3, Batch: 240, Loss: 0.6930093765258789
Epoch: 3, Batch: 250, Loss: 0.6819977164268494
Epoch: 3, Batch: 260, Loss: 0.6267729997634888
Epoch: 3, Batch: 270, Loss: 0.6938235759735107
Epoch: 3, Batch: 280, Loss: 0.6338542103767395
Epoch: 3, Batch: 290, Loss: 0.7480209469795227
Epoch: 3, Batch: 300, Loss: 0.7670654058456421
Epoch: 3, Batch: 310, Loss: 0.7936230301856995
Epoch: 3, Batch: 320, Loss: 0.7015457153320312
Epoch: 3, Batch: 330, Loss: 0.6984924077987671
Epoch: 3, Batch: 340, Loss: 0.6775128841400146
Epoch: 3, Batch: 350, Loss: 0.7232626676559448
Epoch: 3, Batch: 360, Loss: 0.7223442792892456
Epoch: 3, Batch: 370, Loss: 0.641606867313385
Epoch: 3, Batch: 380, Loss: 0.705120325088501
Epoch: 3, Batch: 390, Loss: 0.673150897026062
Epoch: 3, Batch: 400, Loss: 0.7357316613197327
Epoch: 3, Batch: 410, Loss: 0.8306257128715515
Epoch: 3, Batch: 420, Loss: 0.6753929853439331
Epoch: 3, Batch: 430, Loss: 0.6800264716148376
Epoch: 3, Batch: 440, Loss: 0.7912160158157349
Epoch: 3, Batch: 450, Loss: 0.6109472513198853
Epoch: 3, Batch: 460, Loss: 0.626509964466095
Epoch: 3, Batch: 470, Loss: 0.7175719738006592
Epoch: 3, Batch: 480, Loss: 0.7097312211990356
Epoch: 3, Batch: 490, Loss: 0.8013433814048767
Epoch: 3, Batch: 500, Loss: 0.6930856108665466
Epoch: 3, Batch: 510, Loss: 0.8007583618164062
Epoch: 3, Batch: 520, Loss: 0.6753951907157898
Epoch: 3, Batch: 530, Loss: 0.6784454584121704
Epoch: 3, Batch: 540, Loss: 0.6559889316558838
Epoch: 3, Batch: 550, Loss: 0.7597646117210388
Epoch: 3, Batch: 560, Loss: 0.7097688913345337
Epoch: 3, Batch: 570, Loss: 0.5185314416885376
Epoch: 3, Batch: 580, Loss: 0.6920551061630249
Epoch: 3, Batch: 590, Loss: 0.6422823667526245
Epoch: 3, Batch: 600, Loss: 0.6584013104438782
Epoch: 3, Batch: 610, Loss: 0.6091210842132568
Epoch: 3, Batch: 620, Loss: 0.7550024390220642
Epoch: 3, Batch: 630, Loss: 0.6133054494857788
Epoch: 3, Batch: 640, Loss: 0.8517532348632812
Epoch: 3, Batch: 650, Loss: 0.7075152397155762
Epoch: 3, Batch: 660, Loss: 0.6549898386001587
Epoch: 3, Batch: 670, Loss: 0.6851027607917786
Epoch: 3, Batch: 680, Loss: 0.7078498601913452
Epoch: 3, Batch: 690, Loss: 0.6840606927871704
Epoch: 3, Batch: 700, Loss: 0.6717495918273926
Epoch: 3, Batch: 710, Loss: 0.6702673435211182
Epoch: 3, Batch: 720, Loss: 0.7120237350463867
Epoch: 3, Batch: 730, Loss: 0.7378593683242798
Epoch: 3, Batch: 740, Loss: 0.6600288152694702
Epoch: 4, Batch: 10, Loss: 0.6854500770568848
Epoch: 4, Batch: 20, Loss: 0.7589213848114014
Epoch: 4, Batch: 30, Loss: 0.6686308979988098
Epoch: 4, Batch: 40, Loss: 0.6952989101409912
Epoch: 4, Batch: 50, Loss: 0.7086845636367798
Epoch: 4, Batch: 60, Loss: 0.6644229292869568
Epoch: 4, Batch: 70, Loss: 0.6673493385314941
Epoch: 4, Batch: 80, Loss: 0.6177994608879089
Epoch: 4, Batch: 90, Loss: 0.706894040107727
Epoch: 4, Batch: 100, Loss: 0.7258936166763306
Epoch: 4, Batch: 110, Loss: 0.7531775236129761
Epoch: 4, Batch: 120, Loss: 0.6980226039886475
Epoch: 4, Batch: 130, Loss: 0.6864707469940186
Epoch: 4, Batch: 140, Loss: 0.7861132025718689
Epoch: 4, Batch: 150, Loss: 0.6791815161705017
Epoch: 4, Batch: 160, Loss: 0.7607299089431763
Epoch: 4, Batch: 170, Loss: 0.6842501163482666
Epoch: 4, Batch: 180, Loss: 0.6391252875328064
Epoch: 4, Batch: 190, Loss: 0.6779202818870544
Epoch: 4, Batch: 200, Loss: 0.734404444694519
Epoch: 4, Batch: 210, Loss: 0.8177040815353394
Epoch: 4, Batch: 220, Loss: 0.7841715812683105
Epoch: 4, Batch: 230, Loss: 0.7567739486694336
Epoch: 4, Batch: 240, Loss: 0.7415086627006531
Epoch: 4, Batch: 250, Loss: 0.637857973575592
Epoch: 4, Batch: 260, Loss: 0.6985790729522705
Epoch: 4, Batch: 270, Loss: 0.7006288766860962
Epoch: 4, Batch: 280, Loss: 0.6672442555427551
Epoch: 4, Batch: 290, Loss: 0.7355120778083801
Epoch: 4, Batch: 300, Loss: 0.7401593923568726
Epoch: 4, Batch: 310, Loss: 0.7657695412635803
Epoch: 4, Batch: 320, Loss: 0.7110859751701355
Epoch: 4, Batch: 330, Loss: 0.7511646747589111
Epoch: 4, Batch: 340, Loss: 0.6604008078575134
Epoch: 4, Batch: 350, Loss: 0.7140940427780151
Epoch: 4, Batch: 360, Loss: 0.6940369606018066
Epoch: 4, Batch: 370, Loss: 0.6172493696212769
Epoch: 4, Batch: 380, Loss: 0.711220383644104
Epoch: 4, Batch: 390, Loss: 0.6931406259536743
Epoch: 4, Batch: 400, Loss: 0.7471170425415039
Epoch: 4, Batch: 410, Loss: 0.8130796551704407
Epoch: 4, Batch: 420, Loss: 0.6975101232528687
Epoch: 4, Batch: 430, Loss: 0.5963478088378906
Epoch: 4, Batch: 440, Loss: 0.7427645921707153
Epoch: 4, Batch: 450, Loss: 0.6773660182952881
Epoch: 4, Batch: 460, Loss: 0.6617765426635742
Epoch: 4, Batch: 470, Loss: 0.683443009853363
Epoch: 4, Batch: 480, Loss: 0.7177800536155701
Epoch: 4, Batch: 490, Loss: 0.7425591945648193
Epoch: 4, Batch: 500, Loss: 0.7441086769104004
Epoch: 4, Batch: 510, Loss: 0.7906349301338196
Epoch: 4, Batch: 520, Loss: 0.6575209498405457
Epoch: 4, Batch: 530, Loss: 0.6783832907676697
Epoch: 4, Batch: 540, Loss: 0.6692482233047485
Epoch: 4, Batch: 550, Loss: 0.6832329034805298
Epoch: 4, Batch: 560, Loss: 0.7329066395759583
Epoch: 4, Batch: 570, Loss: 0.5831618309020996
Epoch: 4, Batch: 580, Loss: 0.684958815574646
Epoch: 4, Batch: 590, Loss: 0.6640933752059937
Epoch: 4, Batch: 600, Loss: 0.7417047023773193
Epoch: 4, Batch: 610, Loss: 0.6779350638389587
Epoch: 4, Batch: 620, Loss: 0.711896538734436
Epoch: 4, Batch: 630, Loss: 0.6707034707069397
Epoch: 4, Batch: 640, Loss: 0.7902091145515442
Epoch: 4, Batch: 650, Loss: 0.7202293872833252
Epoch: 4, Batch: 660, Loss: 0.6510989665985107
Epoch: 4, Batch: 670, Loss: 0.6915283799171448
Epoch: 4, Batch: 680, Loss: 0.768957257270813
Epoch: 4, Batch: 690, Loss: 0.6823235750198364
Epoch: 4, Batch: 700, Loss: 0.6168761253356934
Epoch: 4, Batch: 710, Loss: 0.6544809937477112
Epoch: 4, Batch: 720, Loss: 0.7373908162117004
Epoch: 4, Batch: 730, Loss: 0.6983019709587097
Epoch: 4, Batch: 740, Loss: 0.7719212174415588
训练开始时间： 2023-03-22 10:34:17
训练结束时间： 2023-03-22 11:01:16
模型训练总时间为: 1618.83 秒
Test accuracy: 0.0

进程已结束，退出代码为 0
